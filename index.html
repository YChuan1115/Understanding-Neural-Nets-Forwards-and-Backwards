---
layout: default
title: {{ Understanding Neural Nets Forwards and Backwards }}
---
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <script type="text/javascript" 
    async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script> 
  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
  <body>
  <h2> Benjamin S. Knight</h2>
  <h4> March 5th, 2017</h4>

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; My goal in writing this is to help foster a better intuition into how neural nets operate. Neural nets have proved revolutionary in pattern inference - for instance, enabling computers to identify and classify images with accuracy that rivals or exceeds that of humans. While neural nets can quickly assume truly daunting levels of complexity, they can be broken down into component parts the underlying mechanics of which are relatively straightforward. A neural network is an ensemble of nodes and the connections between them (also referred to here as 'edges'). These nodes are assembled into layers, with an input layer recieving an input corresponding to an observation (e.g. "Is the pixel red? [yes/no]") and the final layer producing an output (e.g. "Probability that the image is that of an apple: 88%"). These networks may be dozens of layers deep or more, hence the term 'deep-learning.' As information traverses the network, each connection either amplifies or weakens the information passed through it via a system of weights. This stage where information permeates the network, is weighted and reweighted, and is then ultimately used to generate an output is referred to as a 'forward pass.' <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Of course, even the most well-designed neural net won't get things right on the first try. The net needs exposure to additional information in order to learn. This learning mechanism takes the form of updates to the weights assigned to the connections between each node. In the event of a mistake, connections with weights that amplify the flow of information will be penalized more heavily - essentially obstructing that information pathway for subsequent forward passes. The process by which the error signal is generated and then used to update the network's connections is reffered to as 'back propagation,' in that the error signal is propagated backwards through the network from finish to start. <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this post I will walk step-by-step through a single epoch of a simple, three-node neural network. An epoch is defined as one iteration of the model that utilizes the entirety of the avialable training data. For our purposes, the epoch will consist of a single observation. Our hypothetical network has two input variables 'X1' and 'X2', one output variable 'Y', and a training data set that is comprised of a single observation [8, -4]. The interior of the network is comprised of two layers - one hidden layer of two nodes followed by a single node output layer. We can unpack this network further by visualizing the weights as grey squares. Lastly, the activation function that preceeds the output 'Y' is a sigmoid function. The sigmoid function takes the form of the below expression and serves to rescale the results from the neural net so that they reside between zero and one. For classification problems of a True/False nature, a value of 0.49 is far more tractable that -37.4. 
  </p> 

  <div>
    $$
    \sigma(x) = \displaystyle\frac{1}{1+e^{-x}}
    $$
  </div>

  </p> 

  <a name="Figure 1"></a>
  <p align="center"><b>Figure 1: An Example Neural Net</b></p>
  <p align="center">
  <img src="https://github.com/b-knight/Understanding-Neural-Nets-Forwards-and-Backwards/raw/gh-pages/Images_and_GIFs/Establishing_Model_Gif.gif"  width="768" height="432" alt="A GIF showing the construction of a 2-inputs, 1-output, 3-node neural net with a sigmoid activation function in the output layer.">
  </p>

  <h4> One Forward Pass Across a Neural Network </h4>
  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In building a neural net, we typically begin by initializing the weights with small random values chosen from a zero-mean Gaussian distribution (a standard deviation of about 0.01 is often preferred ([Hinton](http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf), 2010, p.9). We start the forward pass by multiplying our initial inputs ('X1' and 'X2') times their respective weights, and then summing the results. Next, we repeat the process for the nodes in the hidden layer - multiplying the output of H1 times its weight, multiplying the output of H2 times its weight, and summing the two products to create the value associated with the output node 'O1'. We conclude the forward pass by applying sigmoid function, thus yielding our initial prediction of 0.21.</p>

  <p align="center"><b>Figure 2: Randomly Assigning Weights and Executing the Forward Pass</b></p>
  <p align="center">
  <img src="https://github.com/b-knight/Understanding-Neural-Nets-Forwards-and-Backwards/raw/gh-pages/Images_and_GIFs/Forward_Pass_GIF.gif"  width="738" height="360" alt="A GIF showing one forward pass of the neural network.">
  </p>

  <h4> What is a Gradient? </h4>
  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An initial forward pass of our model generates a value of 0.21 versus the corect value is 1. The purpose of backwards propagation is to enable us to train the model - typically with some version of gradient descent. To understand how gradient descent is accomplished, it is helpful to know what a gradient is. Below is a visualization of what an error gradient would look like with two variables. In deriving the error gradient, our variables are referred to as 'edges' - the connections between nodes. </p>

 <p align="center"><b>Figure 3: A Three Dimensional Visualization of Gradient Descent</b></p>
  <p align="center">
  <img src="https://github.com/b-knight/Understanding-Error-Signal-Propagation-Forwards-and-Backwards/raw/gh-pages/Images_and_GIFs/Gradient.png" style="border: #000000 1px outset; width: 410 height: 292"
  alt="A Three Dimensional Visualization of Gradient Descent Courtesy of Zoran Vrhovski.">
  </p>
  <p align="center">Source: <a href="https://www.youtube.com/watch?v=wobhkK0h1wc">Zoran Vrhovski</a> May 29th, 2012</p>
 

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A neural net can be thought of as one, very large differentiable equation with many variables. To better understand any complex system with many inputs, it is often useful to specify a relationship between the outcome variable and a specific variable of interest. Mathmatically, we do this by taking the partial derivative of the equation with respect to the variable of interest. When taking the partial derivative, any component of the expression that is not somehow associated with the variable of interest is effectively set to zero. Note in the figure below how different elements drop out of relevance based on what variable we are taking the partial derivative with respect to. </p>
  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For those wanting additional detail, I highly recommend the excellent series of video lectures from <a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient"> Kahn Academy</a>.
 
  <p align="center"><b>Figure 4: Calculating the Propagation of the Error Signal </b></p>
  <p align="center">
  <img src="https://github.com/b-knight/Understanding-Neural-Nets-Forwards-and-Backwards/raw/gh-pages/Images_and_GIFs/Math_Demo.gif" 
       width="768" height="252" alt="A diagram establishing the variables used in backpropagation.">
  </p>

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We previously calculated an output value of 0.21 versus the actual value of 1. How do we use this information to train our network? To illustrate this process of backpropagation I will refer to the above diagram which contains four elements. We have two nodes, <b><i>i</i></b> and <b><i>j</i></b>. <b><i>i</i></b> is located in the penultimate layer - a hidden layer, where as <b><i>j</i></b> is in the output layer. Next, we have the outputs of these two nodes - <b><i>y<sub>i</sub></i></b> for node <b><i>i</i></b> and <b><i>y<sub>j</sub></i></b> for node <i>j</i> respectively. Finally, we have <b><i>z<sub>j</sub></i></b> which is the sum of all of the inputs into node <b><i>j</i></b>.<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Let's begin by assigning our initial output of 0.21 to <b><i>y<sub>j</sub></i></b>. We can subtract the estimated value from the actual value to yield an error of size 0.79. However, neural nets may have hundreds or thousands of output nodes. We need a method of deriving a generalized error signal from all of the output nodes. The function we use for this is typically referred to as the 'loss function.' A very common loss function is the sum of squared errors as shown
  below.</p>

  <div>
    $$
    E = \displaystyle\frac{1}{2}\sum_j(t_j - y_j)^2
    $$
  </div>

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Here the overall error signal generated by the entirety of the neural net is represented as <b><i>E</i></b>. To calculate this value, let's assign the true value of output node <b><i>j</i></b> to <b><i>t<sub>j</sub></i></b>. Taking <b><i>y<sub>j</sub></i></b> and <b><i>t<sub>j</sub></i></b> together, we see that the contents of the parentheses is the difference between the predicted value and the actual value. We are interested in the absolute size of the the error, and so we square the difference. Taking the absolute value would also yield the desired value. However, absolute values are not differentiable - a prerequiste of gradient descent. Next, we sum these squared differences for all of the output nodes. Lastly, we add one half to the loss function for the sake of convenience when we take the derivative. <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now that we have a general error signal, we need to apply it to all of the nodes in the output layer. In other words, we need a way of capturing the extent to which a change in the output of node <b><i>y<sub>j</sub></i></b> impacts the overall level of error, <b><i>E</i></b>. Here is where we convert the derivative of the error with respect to each output node as shown below.</p>

  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial y_j} = -(t_j -y_j) \nonumber \\
    \end{eqnarray}$$
  </div>

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Now that we know the error derivative corresponding to node <b><i>j</i></b>, we need to calculate what amount of error to propagate backwards to all of the nodes that connect to <b><i>j</i></b>. Recall that the sum of all of these precursor nodes is captured by the term <b><i>z<sub>j</sub></i></b>. When we take the partial derivative with respect to these nodes we get the following expression.</p> 

  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial z_j} &=& \displaystyle\frac{dy_j}{dz_j} \displaystyle\frac{\partial E}{\partial y_j}    \nonumber \\
    &=& y_j(1-y_j)\displaystyle\frac{\partial E}{\partial y_j} \nonumber \\
    \end{eqnarray}$$
  </div>

  <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In other words, the change in the amount of total error <b><i>E</i></b> with respect to the sum of inputs to node <b><i>j</i></b> is equal to the change in the the output of node <b><i>j</i></b> with respect to change in the sum of node <b><i>j</i></b>'s inputs multiplied by the change in <b><i>E</i></b> with respect to the output of node <b><i>j</i></b>. Because the term <b><i>z<sub>j</sub></i></b> captures an array of values, its partial derivative is written with a cursive 'd' whereas the other partial derivatives are designated with the more typical Greek  &#948. The resulting value ends up being equal to the output of node <b><i>j</i></b> times one minus the output of node <b><i>j</i></b> all times the partial derivative of the error term <b><i>E</i></b> with respect to the output of node <b><i>j</i></b>.<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Moving backwards from the output layer to the hidden layer, we need to transform node <b><i>j</i></b>'s error derivative in order to apply it to all of the outputs from node <b><i>i</i></b>. In other words, we will use the partial derivative of <b><i>E</i></b> with respect to <b><i>z<sub>j</sub></i></b> to calculate the partial derivative of <b><i>E</i></b> with respect to <b><i>y<sub>i</sub></i></b>.</p>

  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial y_i} = \displaystyle\sum_j\displaystyle\frac{dz_j}{dy_i} \displaystyle\frac{\partial E}{\partial z_j}    \nonumber \\
     = \displaystyle\sum_jw_{ij}\frac{\partial E}{\partial z_j} \nonumber \\
    \end{eqnarray}$$
  </div>

  <p> We can interpret the above expression as follows: The change in the error with respect to the output of a node (<b><i>i</i></b>) is equal to the change in error associated with all inputs to the subsequent node (<b><i>j</i></b>) times the weight of the connection bridging the two nodes (<b><i>W</b></i><sub><b><i>i</i></b> &rarr; <b><i>j</i></b></sub>). We repeat this process for all connections between node <b><i>i</i></b> and the subsequent layer. By summing the results, we derive the total error flowing to node <b><i>i</i></b>.<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can zoom in further and see how this plays out with a particular weight.</p>

  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial w_{ij}} &=& \displaystyle\frac{\partial z_j}{\partial w_{ij}} \displaystyle\frac{\partial E}{\partial z_j}    \nonumber \\
     &=& y_i    \frac{\partial E}{\partial z_j} \nonumber \\
    \end{eqnarray}$$
  </div>

  <p>The change in error with respect to a change in weight <b><i>W</b></i><sub><b><i>i</i></b> &rarr; <b><i>j</i></b></sub> is equal to the change in error with respect to the inputs to the subsequent layer multiplied by the input itself. 

  <a name="Calculating the Gradient"></a>
  <h4> Calculating the Gradient </h4>
  <p> In this section I apply the backpropagation logic discussed in the previous section, and apply it to the neural net shown in <a href="#Figure 1">Figure 1</a>. Based on the notation in Figure 1, input variables are designated as <b><i>X</b></i>, while hidden layer nodes and output layer nodes are represented as <b><i>H</b></i> and <b><i>O</b></i> respectively. We start our backpropagation by taking the error derivative at our sigmoid node as a function of the total error.</p>
  <div>
    $$\begin{eqnarray} 
    \frac{\partial \sigma}{\partial y} = \sigma(y)(1-\sigma(y)) \phantom{aaaa} &\rightarrow& \phantom{aaaa} \frac{\partial E}{\partial \sigma} = (y - \hat{y})\sigma(x)(1- \sigma(x)) \nonumber \\
    \end{eqnarray}$$
  </div>  
  <center><b><i>x</b></i> is the output of the output layer, <b><i>y-hat</b></i> is the predicted value, and <b><i>y</b></i> is the actual value. </center>
  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial y_\sigma} &=& (y - \hat{y})\sigma(x)(1- \sigma(x)) \phantom{aaaa} \nonumber \\
    &=& (1- 0.21)\Bigg(\displaystyle\frac{1}{1+e^{-(-1.28)}}\Bigg)\Bigg(1 - \displaystyle\frac{1}{1+e^{-(-1.28)}}\Bigg) \phantom{aaaa} \nonumber \\
    &=& (1-0.21)(0.21)(1-0.21) \nonumber \\
    &=& (0.79)(0.21)(0.79) \nonumber \\
    &=& 0.131 \nonumber \\
    \end{eqnarray}$$
  </div>  
  <p> Next we take the error derivative of the inputs to the sigmoid node, <b><i>z<sub>&sigma;</sub></b></i>.</p>
  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial z_\sigma} &=& y_\sigma(1-y_\sigma)\displaystyle\frac{\partial E}{\partial y_\sigma} \nonumber \\  
    &=& (0.21)(1-0.21)(0.131) \nonumber \\ 
    &=& 0.0217 \nonumber \\ 
    \end{eqnarray}$$
  </div>
   <p> We use this to calculate the error signal propagated to the two hidden nodes, <b><i>H<sub>1</sub></b></i> and <b><i>H<sub>2</sub></b></i>.</p>
  <div>
    $$\begin{eqnarray} 
    \frac{\partial E}{\partial W_{H_1\rightarrow\sigma}} &=& H_1    \frac{\partial E}{\partial z_\sigma} \nonumber \phantom{aa}  \rightarrow \phantom{aa}  (-0.8)(0.0217) \phantom{aa}  \rightarrow \phantom{aa} -0.01736\\
    \frac{\partial E}{\partial W_{H_2\rightarrow\sigma}} &=& H_1    \frac{\partial E}{\partial z_\sigma} \nonumber \phantom{aa}  \rightarrow \phantom{aa}  (1.2)(0.0217) \phantom{aaa}  \rightarrow \phantom{aa} 0.02604 \nonumber\\
    \end{eqnarray}$$
  </div>
  <p> Now that we have all of the error derivatives, we can employ gradient descent. In adjusting the weights for the output layer (<b><i>W<sub>2a</sub></i></b>, <b><i>W<sub>2b</sub></i></b>), we multiply together (1.) the learning rate paramater - <i>eta</i> (2.) the output unit error, and (3.) the hidden unit activation value. Let us assign a value of 0.5 for <i>eta</i>. For the hidden unit activation value, recall that
  <div>
  $$\begin{eqnarray} 
  y_{H_1\rightarrow\sigma} &=& (H_1)(W_{H_1\rightarrow\sigma}) \phantom{aa}  \rightarrow \phantom{aa} (-0.8)(0.7) \phantom{aa}  \rightarrow \phantom{aa} -0.56 \nonumber\\
  y_{H_2\rightarrow\sigma} &=& (H_2)(W_{H_2\rightarrow\sigma}) \phantom{aa}  \rightarrow \phantom{aa} (1.2)(-0.6) \phantom{aa}  \rightarrow \phantom{aa} -0.72 \nonumber\\
  \end{eqnarray}$$
  </div>
  <p> Given these inputs, the changes to the weights feeding the neural net's output layer are calculated as follows.
  <div>
  $$\begin{eqnarray} 
  \Delta W_{H_1\rightarrow\sigma} &=& (\eta)\Big(\frac{\partial E}{\partial y_\sigma}\Big)(y_{H_1\rightarrow\sigma}) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(0.131)(-0.56) \phantom{aa}  \rightarrow \phantom{aa} -0.036 \nonumber \\
  \Delta W_{H_2\rightarrow\sigma} &=& (\eta)\Big(\frac{\partial E}{\partial y_\sigma}\Big)(y_{H_1\rightarrow\sigma}) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(0.131)(-0.72) \phantom{aa}  \rightarrow \phantom{aa} -0.047 \nonumber \\
  \end{eqnarray}$$
  </div>
  <p> With the new weights in hand, we can see that we are slightly decreasing the flow of infomation between both the <b><i>H<sub>1</sub></i></b> node and the sigmoid node (0.7 - 0.036 &rarr; 0.664) as well as between the <b><i>H<sub>2</sub></i></b> node and the sigmoid node (-0.6 - 0.047 &rarr; -0.647).<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Moving on to the weights in the preceeding layer (<b><i>W<sub>1a</sub></i></b>, <b><i>W<sub>1b</sub></i></b>, <b><i>W<sub>1c</sub></i></b>, <b><i>W<sub>1d</sub></i></b>), we adjust the updating formula slighty. The change in weights between the input layer and the hidden layer is calculated by multiplying together (1.) the learning rate, (2.) the hidden unit's error, and (3.) the input values, <b><i>X<sub>1</sub></i></b> = 8 and <b><i>X<sub>2</sub></i></b> = -4.
  <div>
  $$\begin{eqnarray} 
  \Delta W_{X_1\rightarrow H_1} &=& (\eta)\Big( \frac{\partial E}{\partial W_{H_1\rightarrow\sigma}}\Big)(X_1) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(-0.01736)(8) \phantom{aaaa}  \rightarrow \phantom{aa} -0.069 \nonumber \\
  \Delta W_{X_1\rightarrow H_2} &=& (\eta)\Big( \frac{\partial E}{\partial W_{H_2\rightarrow\sigma}}\Big)(X_1) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(0.02604)(8) \phantom{aaaaaa}  \rightarrow \phantom{aaaa} 0.104 \nonumber \\
  \Delta W_{X_2\rightarrow H_1} &=& (\eta)\Big( \frac{\partial E}{\partial W_{H_1\rightarrow\sigma}}\Big)(X_2) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(-0.01736)(-4) \phantom{aaa}  \rightarrow \phantom{aaaa} 0.034 \nonumber \\
  \Delta W_{X_2\rightarrow H_2} &=& (\eta)\Big( \frac{\partial E}{\partial W_{H_2\rightarrow\sigma}}\Big)(X_2) \phantom{aa}  \rightarrow \phantom{aa} (0.5)(0.02604)(-4) \phantom{aaaaa}  \rightarrow \phantom{aa} -0.052 \nonumber \\
  \end{eqnarray}$$
  </div>
 

<h4> Final Thoughts </h4>

  <h3> References </h3>
  	<ul style="list-style-type:disc">
  		<li> Hinton, Geoffrey. [Artificial Intelligence Courses]. (2013, November 4th). <b>The Backpropagation Algorithm</b>. 
  		<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retrieved from <a href="https://www.youtube.com/watch?v=xfPz92B0rv8">https://www.youtube.com/watch?v=xfPz92B0rv8</a>.</li>
  		<li> Hinton, Geoffrey. (2010). A Practical Guide to Training Restricted Boltzmann Machines. 
  		<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retrieved from <a href="http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf">http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf</a>.</li>
  		<li> Karpathy, Andrej. [MachineLearner]. (2016, June 14th). <b>CS231n Lecture 4 - Backpropagation, Neural Networks</b>. 
  		<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Retrieved from <a href="https://www.youtube.com/watch?v=QWfmCyLEQ8U">https://www.youtube.com/watch?v=QWfmCyLEQ8U</a>.</li>
  	</ul> 
  </body>
</html>

